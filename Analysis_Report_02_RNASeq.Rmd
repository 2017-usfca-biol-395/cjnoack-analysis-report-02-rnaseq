---
title: "Analysis Report 2: Your Title Here"
author: "Chelsea Noack"
date: "November 10, 2017"
output: github_document
bibliography: references.bib
csl: bioinformatics.csl
---

*Overall, a single-spaced page is about 500 words. So if the guidelines say half of a page, think about writing around 250 words. You can use the wordcountaddin in RStudio to track your progress.*

# Introduction

Add about 1 page here. Must cite at least 5 peer reviewed articles.

# Methods

## Sample origin and sequencing

The data comes from Seo et al.'s 2012 paper *The transcriptional landscape and mutational profile of lung adenocarcinoma*. Seo et al. took fresh surgical samples of normal and cancerous tissues from  200 Korean patients. The patients had primary lung adenocarcinoma and recently underwent lung resection. For their transcriptional study between smokers and non-smokers, which pertains to Li et al.'s study, they used about 70 of those 200 samples. The samples were normal and cancerous tissues from 34 smokers and 34 never-smokers. Within the smoking category was current smoking and those whom have smoked. They also recorded gender, cancer stage, and smoking status from the patients [@seo2012transcriptional]. 

To sequence the samples, they did transcriptome sequencing combine with whole-exome and transcriptome sequencing. Transcriptome sequencing has a past history of detecting somatic mutations in cancer. The combination made their study the first large scale-study of lung adenocarcinoma using RNA sequencing [@seo2012transcriptional]. 

Li et al. (2015) downloaded Seo et al.'s RNAseq data from GEO, Gene Expression Omnibus. In doing so, they could perform a comprehensive pair-wise comparison analysis. From the data, they had 14 billion paired-end sequence reads ranging to 101 bp in length [@li2015rna].  They excluded the data from any patients under the age of 75 for better comparison. Once they confirmed a paired-nature of the RNA-seq data of normal vs. tumor tissue, they used Ensembl GRCh37 Tophat to align the reads to the human genome. To count the reads by genes, they used HTSeq [@li2015rna]. For the differential gene expression analysis, they used R Bioconductor edgeR. Next, Li et al. had to filter the data. Genes with 1 count per million (cpm) in atleast half the sample size were included. From there, we took their edited and filtered data for our analysis. 

## Computational

First, Dr. Napauka Zimmerman downloaded the files from the NCBI Sequence Read archive under the study number ERP001058. Downloaded the extensive amount of data was made easier by the BioMartr package. Biomartr is a package in CRAN which helps retrieve metagenomic data and functional annotation retrieval. It is more polished than NCBI. Next, the files were converted from SRA to fastq. 

Because the files were so massive, Zimmerman had to use Sailfish. Sailfish is a package which quantifies the abundance of previously annotated RNA isoforms from RNA-seq data, and in doing so avoids mapping reads [@patro2014sailfish]. This makes it 20 times faster than alternative methods and still maintains a level of accuracy. This is ideal for processing large amounts of sequencing reads. Once the files were processed, they were put through fastQC, a quality checking program, which eliminated many reads which were very low quality. The QC reports are helpful to see how viable each sequence is for analysis; if the majority of the sequence is above a 30 score, then we consider it to be sequenced well. Typically, the 3' end will deteriorate, which is normal. 

The next step was to put the files through paired-end Trimmomatic. Specifically, it clipped off Illumina adapters and any reads with a quality score less than 20. The trimmed, quality-checked sequences then needed to be aligned. Sailfish efficiently aligned the sequences using k-mers.  As mentioned before, Sailfish is fast; each sample is parsed out. 88 cores were used in an overnight run. Finally, with parsed sequences efficiently aligned, Zimmerman built the tables. Within our table, each row is a human gene name and the column is different samples in all the groups. The table was melted so it included the metadata and original data. Dplyr and ggplot help us analyze the data from the melted tables. 

# Results

In addition to a minimum of 4-5 figures/tables (and associated captions), you should include sufficient text in this section to describe what your findings were. Remember that in the results section you just describe what you found, but you don't interpret it - that happens in the discussion.

```{r load-libraries, message = FALSE, echo = FALSE}
# Be sure to install these packages before running this script
# They can be installed either with the intall.packages() function
# or with the 'Packages' pane in RStudio

# load general-use packages
library("dplyr")
library("tidyr")
library("knitr")
library("ggplot2")
library("magrittr")

# this package allows for the easy inclusion of literature citations in our Rmd
# more info here: https://github.com/crsh/citr
# and here:
# http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
library("citr")
```

```{r load-data, message = FALSE, echo = FALSE}
# load the dataset from a compressed binary file
# it gets loaded as an object called "final_table"
# this has 3.4 million rows...so you will need to be thoughtful about
# how you analyze the data so that you don't overwhelm your laptop
load("output/final_compiled_counts/joined_count_data.RData")

# changes all columns names to lower case so Travis doesn't complain
names(final_table) %<>% tolower

# test that it loaded correctly before proceeding
stopifnot(exists("final_table"))
```

```{r make-summary-table, echo = FALSE}
# There are many many genes in this dataset, so we can
# subset it down to just a few here to look for interesting patterns
# in the most highly expressed
top_15 <- final_table %>%
  group_by(gender, genename) %>%
  summarize(mean_count = mean(counts_lengthscaledtpm)) %>%
  arrange(desc(mean_count)) %>%
  head(n = 15)

# then we can use the `kable()` function to make a nicely formatted
# markdown table
top_15 %>%
  kable()
```

**Table 1**: The most highly expressed genes in both genders included *SFTPB* and *EEF1A1*.

```{r make-barplot-of-highly-expressed-genes, echo = FALSE}
# this code uses the same data as above, but use it to make a
# barplot - remember geom_col() is just like
# when you use geom_bar(stat = "identity")
top_15 %>%
  ggplot(aes(x = genename,
             y = mean_count,
             fill = gender)) +
    geom_col(position = "dodge")
```

**Figure 1**: Here we show an example figure caption.

```{r make-boxplot-of-highly-expressed-genes, echo = FALSE}
# here we just want to pull out the unique gene names and turn
# them into a vector so we can use it below to make a boxplot
# we use the pull() funtion to get this as a vector, just like
# we did when making histograms several weeks ago
top_genes <- top_15 %>%
  ungroup() %>%
  select(genename) %>%
  unique() %>%
  pull()

# now we need to filter from the full data set again, because
# we don't just want summary data, we want all the data in
# order to make boxplots
final_table %>%
  filter(genename %in% top_genes) %>%
  ggplot(aes(x = genename,
             y = age_at_diagnosis,
             fill = gender)) +
    geom_boxplot() +
    facet_wrap(~cancer_stage) +
    xlab("Gene Name") +
    ylab("Age of diagnosis per gene") +
    ggtitle("Age of diagnosis per gene by gender and cancer stage") +
    theme_bw() + # simplifies theme
    theme(axis.text.x = # rotates x axis labels vertically
            element_text(angle = 90,
                         hjust = 1))
```

**Figure 2**: Here we show another example figure caption.

# Discussion

1-2 pages is 500 to 1,000 words. 

Add around 1-2 pages interpreting your results and considering future directions one might take in analyzing these data.

# Sources Cited
